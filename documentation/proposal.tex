\documentclass[12pt,letterpaper,titlepage]{report}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{float}
\usepackage{titlesec}
\usepackage{needspace}
\usepackage{hyperref}
\usepackage{siunitx}
\usepackage[width=8.50in, height=11.00in, left=1.00in, right=1.00in, top=1.00in, bottom=1.00in]{geometry}
\usepackage[backend=bibtex,style=ieee]{biblatex}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\newcommand\pythonstyle{\lstset{
		language=Python,
		basicstyle=\ttm,
		otherkeywords={self},             % Add keywords here
		keywordstyle=\ttb\color{deepblue},
		emph={MyClass,__init__},          % Custom highlighting
		emphstyle=\ttb\color{deepred},    % Custom highlighting style
		stringstyle=\color{deepgreen},
		frame=tb,                         % Any extra options here
		showstringspaces=false            % 
}}

% Python environment
\lstnewenvironment{python}[1][]
{
	\pythonstyle
	\lstset{#1}
}
{}

% Python for external files
\newcommand\pythonexternal[2][]{{
		\pythonstyle
		\lstinputlisting[#1]{#2}}}

% Python for inline
\newcommand\pythoninline[1]{{\pythonstyle\lstinline!#1!}}

% Variables
\titleformat{\section}
{\needspace{8\baselineskip}\Large\bfseries}{\thesection}{1em}{}


% Document start ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\title{Neural network-based controller}
\author{Justin Ng}
\bibliography{bib} 

\begin{document}
\pagenumbering{gobble}
\includepdf{titlepage}
\newpage
\pagenumbering{roman}
\tableofcontents
\listoffigures
\listoftables


\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}
I would like to thank everyone for everything.


\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\textbf{Note}: All project files can be found at \url{https://www.github.com/okayjustin/roborodentia2017} \

Artificial neural networks (ANNs) are highly-capable alternatives to traditional problem solving schemes due to their ability to solve non-linear systems with a non-algorithmic approach. The applications of ANNs range from process control to pattern recognition and, with increasing importance, robotics. This paper demonstrates continuous control of a robot using an actor-critic algorithm based on deep deterministic policy gradients (DDPG) originally conceived by Google DeepMind. The robot performs tasks such as locomotion within an enclosed area and object transportation. The paper also details the robot design process and explores the challenges of implementation in a real-time system.


\chapter{Introduction}
\pagenumbering{arabic}
\section{Definitions and Assumptions}
The robot is designed to only travel within a rectangular closed area of eight feet in the x direction and five feet in the y direction. The coordinate system is chosen as Cartesian with the origin placed at the bottom-left corner of the field. The position of the robot is always in the xy-plane since it cannot move vertically (z = 0). Therefore, $x$ refers to the robot position along the x-axis and ranges from 0 to 8 feet, and $y$ refers to position along the y-axis and ranges from 0 to 5 feet. Additionally, the robot can only rotate around the z-axis so $\theta$ refers to the angle of the robot in the xy-plane. Maintaining standard Cartesian coordinates, $\theta=\ang{0}$ is along the positive x direction while $\theta=\ang{90}$ is along the positive y direction.

\section{Kalman Filters}
The system relies on several different sensors to determine where it is within the environment, a problem commonly referred to as robot localization. The \textit{Kalman Filter} (KF), an optimal state estimator, performs noise filtering and sensor fusion, the process of combining measurements from multiple sensors. The filter operates on the principles of Bayesian inference and uses statistically noisy measurements over time and knowledge of the system to produce a more accurate estimate of an unknown variable than with measurement alone.

\subsection{Algorithm}
The Kalman Filter algorithm and equations are reproduced here from Roger Labbe's excellent interactive online book \autocite{labbe_2017}.  The algorithm consists of two stages (not including initialization): prediction and update. During the first stage, the filter uses the current state and a process model (typically a function of time) to estimate the state in the next time step along with its uncertainty. The second stage uses sensor measurements to update the estimation by taking a weighted average based on the ratio of uncertainty between the prediction and measurement. 

\subsubsection*{Initialization}
Before the first run of the filter, initialize the estimated state (\textbf{x}, also called the posterior) and estimated state covariance matrix (\textbf{P}).
\subsubsection*{Predict}
During the predict phase, the process model is used to predict the future state (known as the prior) (\textbf{\=x}) after one time step by summing the posterior (\textbf{x}) multiplied by the \textit{state transition function} (\textbf{F}) with the control input model (\textbf{B}) multiplied by the control input (\textbf{u}). The covariance of prior (\textbf{\=P}) is larger than the posterior covariance (\textbf{P}) due to uncertainty in the process model (\textbf{Q}).
\begin{align*}
\bar{\textbf{x}} &= \textbf{Fx} + \textbf{Bu}\\
\bar{\textbf{P}} &= \textbf{FPF}^T + \textbf{Q}\\
\end{align*}

\subsubsection*{Update}
Make measurements (\textbf{z}, measurement mean) and determine their accuracy (\textbf{R}, measurement noise covariance). Calculate the residual (or difference) (\textbf{y}) between the measurement and the product of the measurement function (\textbf{H}) and the prior from the previous phase. \textbf{H} converts the prior from the state space to the measurement space. Calculate the weighting factor (\textbf{K}, Kalman gain), valued between 0 and 1, based on the whether the measurement or prior is more accurate. Set the new posterior, \textbf{x}, to an average of the measurement and prior, weighted by \textbf{K}. Finally, update the posterior's covariance, \textbf{P}, based on the measurement certainty. The algorithm then loops back to the predict phase using the newly-calculated posterior.
\begin{align*}
\textbf{y} &= \textbf{z} - \textbf{H}\bar{\textbf{x}}\\
\textbf{K} &= \bar{\textbf{P}}\textbf{H}^T(\textbf{H}\bar{\textbf{P}}\textbf{H}^T+\textbf{R})^{-1}\\
\textbf{x} &= \bar{\textbf{x}} + \textbf{Ky}\\
\textbf{P} &= (\textbf{I}-\textbf{KH})\bar{\textbf{P}}\\
\end{align*}

\subsection{Design}
The desired state variable \textbf{x} is chosen as the linear position, velocity, and acceleration in the x and y directions as well as the angular position, velocity, and acceleration about the z-axis:
\begin{align*}
\textbf{x} &= [x\ y\ \theta]^T\\
\dot{\textbf{x}} &= [\dot{x}\ \dot{y}\ \dot{\theta}]^T\\
\ddot{\textbf{x}} &= [\ddot{x}\ \ddot{y}\ \ddot{\theta}]^T\\
\end{align*}
The process model for position and velocity:
\[ \begin{cases} 
	\bar{x}=x+\dot{x}\Delta t+0.5\ddot{x}(\Delta t)^2\\
	\bar{\dot{x}}=\dot{x}+\ddot{x}\Delta t\\
	\bar{\ddot{x}}=\ddot{x}\\
\end{cases} \]
Which can be written in the form:
\begin{align*}
\begin{bmatrix}\bar{x}\\ \bar{\dot{x}}\\ \bar{\ddot{x}} \end{bmatrix} &=
\begin{bmatrix}1 & \Delta t & 0.5(\Delta t)^2 \\
0 & 1 & \Delta t \\
0 & 0 & 1 \\\end{bmatrix}
\begin{bmatrix}x\\ \dot{x}\\ \ddot{x} \end{bmatrix}\\ 
\bar{\textbf{x}}&=\textbf{F}\textbf{x}
\end{align*}
The measurement vector is chosen as:
\[\textbf{z}=
\begin{bmatrix}z_x & z_{\ddot{x}} & z_y & z_{\ddot{y}} & z_{\theta} & z_{\dot{\theta}} \end{bmatrix}^T\]
The measurement noise matrix is shown below. The off-diagonals are 0 because the noise between sensors is assumed to be uncorrelated.
\[\textbf{R}=
\begin{bmatrix}\sigma^2_x & 0 & 0 & 0 &0 & 0\\
0 & \sigma^2_{\ddot{x}} & 0 & 0 & 0 & 0\\
0 & 0 & \sigma^2_y & 0 & 0 & 0 \\
0 & 0 & 0 & \sigma^2_{\ddot{y}} & 0 & 0\\
0 & 0 & 0 & 0 & \sigma^2_{\theta} & 0\\
0 & 0 & 0 & 0 & 0 & \sigma^2_{\dot{\theta}} \end{bmatrix}\]


\chapter{Project Plan (draft)}
\section{Problem}
Create a competition robot for Roborodentia and control it using neural networks.

\section{Solution}
Design and manufacture a robot. Write firmware with a neural network implementation and train it to perform competition tasks. 

\section{Objectives}
\begin{itemize}
	\item Select robot design criteria.
	\item Create several solutions and prototype a few proof-of-concepts.
	\item Design electrical systems:
	\begin{itemize}
		\item Power systems: Batteries, regulation, distribution.
		\item Microcontroller: sufficient processing power and IO.
		\item Sensors: dependent on control strategy. What information needed?
		\item Actuators
	\end{itemize}
	\item Model robot in SolidWorks with attention to manufacturing.
	\item Order parts and manufacture robot.
	\item Bring up electrical system and perform functional checks.
	\item Design neural network and training plan.
	\item Develop firmware: neural network, FSM design, communications, debug code.
	\item Train network and tune.
	\item Revise mechanical/electrical/firmware and repeat.
\end{itemize}


\section{Tasks and Timeline}



\chapter{\LaTeX\ Usage}

\section{Figures and Ref}
This is where I introduce stuff. See Figure \ref{fig:padthai}.

\begin{figure}[H]   % [h] means here
	\centering
	\includegraphics[width=3.6in]{images/padthai.jpg}
	\caption{Pad thai}
	\label{fig:padthai}
\end{figure}



\section{Math}

\begin{equation}
	f(x) = x^2
\end{equation}


This is an equation that we don't want to number: $$f(x) = x^2$$

Here's an in-line equation: $f(x) = x^2$.

Here's an aligned equation: Aligns at the \&.
\begin{align*}
	1 + 2 & = 3                       \\
	1     & = 3 - 2                   \\
	f(x)  & = x^2                     \\
	g(x)  & = \frac{1}{x}             \\
	F(x)  & = \int^a_b \frac{1}{3}x^3 \\
	\frac{1}{\sqrt{x}}
\end{align*}

\[\begin{bmatrix}
		a & \lambda \\
		c & d
	\end{bmatrix}\]



\section{Citations}


Random citation \autocite{nguyen_widrow_1990} embeddeed in text.

Random citation \autocite{DUMMY:1} embeddeed in text.

Random citation \autocite{nguyen_widrow_1990} embeddeed in text.
\autocite{negenborn_2003} \autocite{labbe_2017}

\section{Accents}

Premi\`ere	\.x

\section{Dashes}

The space is 3-dimensional.

Read pages 3--4.

I saw them---there were 3 men alive

The temperature dropped to $-$3 degrees.

\section{Lists}

\begin{itemize}
	\item  First Level
	      \begin{itemize}
		      \item  Second Level
		            \begin{itemize}
			            \item  Third Level
			                  \begin{itemize}
				                  \item  Fourth Level
			                  \end{itemize}
		            \end{itemize}
	      \end{itemize}
\end{itemize}
\begin{enumerate}
	\item First level item
	\item First level item
	      \begin{enumerate}
		      \item Second level item
		      \item Second level item
		            \begin{enumerate}
			            \item Third level item
			            \item Third level item
			                  \begin{enumerate}
				                  \item Fourth level item
				                  \item Fourth level item
			                  \end{enumerate}
		            \end{enumerate}
	      \end{enumerate}
\end{enumerate}

\section{Groups}
 {
  \hsize = 4 in
  \parindent = 0 pt
  \leftskip = 1 in
  will produce a paragraph that is four
  (this is an easy mistake to make).
  \par
 }


\section{Code highlighting}

\begin{python}
	class MyClass(Yourclass):
	def __init__(self, my, yours):
	bla = '5 1 2 3 4'
	print bla
\end{python}


\chapter{Control Problem}

\chapter{Training Algorithm}

\chapter{Implementation}

\chapter{Results}

\chapter{Conclusion}

\renewcommand\bibname{References}
\printbibliography
\addcontentsline{toc}{chapter}{References}

\chapter*{Appendices}
\addcontentsline{toc}{chapter}{Appendices}


\end{document}